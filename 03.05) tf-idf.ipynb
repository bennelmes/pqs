{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "539ebe2b-8a5b-48dc-a6de-df2a5337eeb3",
   "metadata": {},
   "source": [
    "## tf-idf calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3f0f8b5-edcb-4c25-bf97-8b239e560c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fbb5ea8-5259-4dd7-89ad-104e6f8f673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wpqs = pd.read_csv('cleaned.csv')\n",
    "wpqs['cleanedQuestion'].fillna('', inplace=True)\n",
    "wpqs['topic'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1327eb-cfde-4da5-bb07-fff9938e199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wpqs[['cleanedQuestion', 'topic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3badbe7-ff36-4f14-a720-7a57a58c1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data.cleanedQuestion.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6eac7d-6408-4e50-b2a4-ec497ca5321e",
   "metadata": {},
   "source": [
    "Instantiate and transform the vectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b195c7c0-7152-4e11-b24e-87757cc4898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/miniconda3/envs/lan/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tf_idf_vect = TfidfVectorizer()\n",
    "X_train_tf_idf = tf_idf_vect.fit_transform(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bace647a-41a7-4ba0-b7bd-e016f390ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = tf_idf_vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49f731f8-505a-47e8-aeca-ab8950ad9a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words = 'english', min_df = 3, max_df=0.5, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2f8cabc-a6b8-4ff8-91d8-55e7b3d64d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = cvec.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bba2680a-7575-4ed3-a51e-95026cc5b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/miniconda3/envs/lan/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "transformer = TfidfTransformer()\n",
    "transformed_weights = transformer.fit_transform(sf)\n",
    "weights = np.asarray(transformed_weights.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': cvec.get_feature_names(), 'weight': weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63718d05-c08a-4400-b147-322fa7d88238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b55224b3-d8af-4b31-a5d7-e8e82e643f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71274</th>\n",
       "      <td>department</td>\n",
       "      <td>0.017528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25769</th>\n",
       "      <td>assessment</td>\n",
       "      <td>0.013007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232599</th>\n",
       "      <td>steps</td>\n",
       "      <td>0.011686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250244</th>\n",
       "      <td>uk</td>\n",
       "      <td>0.010810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41257</th>\n",
       "      <td>care</td>\n",
       "      <td>0.010371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175065</th>\n",
       "      <td>plans</td>\n",
       "      <td>0.009816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227174</th>\n",
       "      <td>social</td>\n",
       "      <td>0.009626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239892</th>\n",
       "      <td>taking</td>\n",
       "      <td>0.009532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108123</th>\n",
       "      <td>government</td>\n",
       "      <td>0.009068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227185</th>\n",
       "      <td>social care</td>\n",
       "      <td>0.008786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               term    weight\n",
       "71274    department  0.017528\n",
       "25769    assessment  0.013007\n",
       "232599        steps  0.011686\n",
       "250244           uk  0.010810\n",
       "41257          care  0.010371\n",
       "175065        plans  0.009816\n",
       "227174       social  0.009626\n",
       "239892       taking  0.009532\n",
       "108123   government  0.009068\n",
       "227185  social care  0.008786"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_df.sort_values('weight', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1769756-687b-4a41-ad08-30f08d53b6d2",
   "metadata": {},
   "source": [
    "## Gensim tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f02467bd-e2fe-476e-b1d6-d7fbb273c8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ben/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ben/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e06c185-3ed6-493b-8d77-2a6b6200ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44adaa6-3434-4687-bd57-94a9d1c0f5b5",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2571c22d-ad45-4e1c-b1fa-cd9dbb5fcd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76524/959812244.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_text['index'] = data_text.index\n"
     ]
    }
   ],
   "source": [
    "# Prepare our text\n",
    "\n",
    "data_text = wpqs[['cleanedQuestion']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da531695-7d60-406d-8f06-8a854d3f207d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385107\n",
      "                                     cleanedQuestion  index\n",
      "0  how much has been paid through working tax cre...      0\n",
      "1  what the value was of the average claim for ta...      1\n",
      "2  what the total value was of tax credits paid t...      2\n",
      "3  how many self-employed people claimed (a) chil...      3\n",
      "4  how many families in (a) york central constitu...      4\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n",
    "print(documents[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac37cb0-7e67-435d-afe9-3f2385c78110",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58103db3-6a28-4ca6-a0e9-2648e4265728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f30edf6-9e09-47b8-a1f5-1dcb33e6388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['if', 'he', 'will', 'meet', 'the', 'hon.', 'member', 'for', 'middlesbrough', 'south', 'and', 'east', 'cleveland', 'to', 'discuss', 'the', 'proposed', 'closure', 'of', '(a)', 'minor', 'injuries', 'units', 'at', 'guisborough', 'and', 'east', 'cleveland', 'hospitals', '(b)', 'skelton', 'medical', 'centre', '(c)', 'p']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "stem() missing 1 required positional argument: 'token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_76524/1994894650.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n tokenized and lemmatized document: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_76524/1147093185.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTOPWORDS\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatize_stemming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_76524/1147093185.py\u001b[0m in \u001b[0;36mlemmatize_stemming\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlemmatize_stemming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: stem() missing 1 required positional argument: 'token'"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e5aff50-b954-47e7-8dae-50122f31bde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if he will meet the hon. member for middlesbrough south and east cleveland to discuss the proposed closure of (a) minor injuries units at guisborough and east cleveland hospitals (b) skelton medical centre (c) p'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f2fdb-891e-4313-8749-f3f061af6d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
